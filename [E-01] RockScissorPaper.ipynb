{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883819c3",
   "metadata": {},
   "source": [
    "# 미니 프로젝트 : Rock_Scissor_Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d4a333",
   "metadata": {},
   "source": [
    "## PIL 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38a9686a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860948e1",
   "metadata": {},
   "source": [
    "## 이미지 사이즈 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef66fe14",
   "metadata": {},
   "source": [
    "#### 가위 - 이미지의 크기 28x28로 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7716751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f59f6f0",
   "metadata": {},
   "source": [
    "#### 바위 - 이미지의 크기 28x28로 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf2a6eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f142ee",
   "metadata": {},
   "source": [
    "#### 보 - 이미지의 크기 28x28로 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7ea163a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154cd91e",
   "metadata": {},
   "source": [
    "## 데이터읽기 및 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f041642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd95460c",
   "metadata": {},
   "source": [
    "## 이미지 불러오기 (x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "211a03be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4431a7",
   "metadata": {},
   "source": [
    "## 네트워크 설계하기\n",
    "### 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1df0036e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 31,050\n",
      "Trainable params: 31,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977a9a52",
   "metadata": {},
   "source": [
    "## 네트워크 모델 학습시키기\n",
    "#### epochs 값은 10으로 지정하여 모델을 학습시킨다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a625feff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 2/15\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 3/15\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 4/15\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 5/15\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 6/15\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 7/15\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 8/15\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 9/15\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 10/15\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 11/15\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 9.9097e-04 - accuracy: 1.0000\n",
      "Epoch 12/15\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 8.9019e-04 - accuracy: 1.0000\n",
      "Epoch 13/15\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 7.7577e-04 - accuracy: 1.0000\n",
      "Epoch 14/15\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 7.2705e-04 - accuracy: 1.0000\n",
      "Epoch 15/15\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 6.6372e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faa6cd39670>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy', #오류제거\n",
    "             metrics=['accuracy'])  #평가지표\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0efd2e6",
   "metadata": {},
   "source": [
    "## 모델 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b5114dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500  images to be resized.\n",
      "1500  images resized.\n",
      "1500  images to be resized.\n",
      "1500  images resized.\n",
      "1500  images to be resized.\n",
      "1500  images resized.\n",
      "학습데이터(x_train)의 이미지 개수는 4500 입니다.\n",
      "x_test shape: (4500, 28, 28, 3)\n",
      "x_test_norm shape: (4500, 28, 28, 3)\n",
      "y_test shape: (4500,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper_test1/rock\" # 경로는 하위폴더로 설정\n",
    "resize_images(image_dir_path)  # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper_test1/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper_test1/paper\"\n",
    "resize_images(image_dir_path)\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper_test1\"\n",
    "(x_test, y_test)=load_data(image_dir_path, 4500)\n",
    "\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"x_test_norm shape: {}\".format(x_test_norm.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e875b02c",
   "metadata": {},
   "source": [
    "## 학습 결과 확인\n",
    "### 정확도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "754e04ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 - 0s - loss: 4.4992 - accuracy: 0.6078\n",
      "test_loss: 4.499218463897705 \n",
      "test_accuracy: 0.6077777743339539\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf41cdf",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65d4bd3",
   "metadata": {},
   "source": [
    "### Aiffle에서 진행하는 첫 번째 프로젝트!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6fdbbc",
   "metadata": {},
   "source": [
    "#### 좋았던 점\n",
    "- 내가 직접 데이터를 생성해서 하다보니 신기했다\n",
    "- 다른 사람들과 오류가 발생하는 부분도 같이 해결하고 이런 방법을 사용하면 정확도가 조금 더 좋게 나온다 등등의 다양한 이야기를 나눌 수 있어서 좋았다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe82eedf",
   "metadata": {},
   "source": [
    "#### 어려운 점 & 알게된 점 & 개선하기 위해 했던 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f17b602",
   "metadata": {},
   "source": [
    "- 이번 프로젝트에서 어려웠던 점은 생각보다 결과가 너무 안좋아서 다른 해결방법을 찾아보는 것이 어려웠다.\n",
    "- 프로젝트를 진행하면서 알게된 점\n",
    "\n",
    "     1. 다른 사람의 가위바위보 자료를 가지고 와서 test해볼때 사이즈를 설정하는 부분에서 많이 오류가 났다. 그래서 자세히 보니 위에서 이미지 사이즈를 28x28로 변경했었는데 이번에 test하려고 가지고 온 사진에도 사이즈 변경하는 것이 필요하다는 것을 알게 되었다. 그리고 경로를 가장 하위 폴더로 해두어야 하는 데 경로를 잘 못 설정해서 더 더욱 오류가 났었다.\n",
    "     2. 그리고 처음에 데이트를 시켜보았을때 정확도가 33% 가 나왔다. 그래서 또 어떤 점이 문제인가 했더니 학습 데이터가 많을수록 인식률이 높아진다는 것을 알게 되었다. \n",
    "     \n",
    "- 이후 더 많은 양의 데이터로 정확도를 확인한 결과 60.78%까지 올라갈 수 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc96e37",
   "metadata": {},
   "source": [
    "### 마지막으로 다음에는 조금 더 다양한 방법으로 결과를 내보고 싶다!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
